import spacy
import re
import os
from datetime import datetime, timezone

nlp = spacy.load("en_core_web_md")

def classify_entities(entities):
    education_keywords = ["university", "college", "institute", "bachelor", "master", "phd", "msc", "school", "academy"]
    skill_keywords = [
        # üß† –ú‚Äô—è–∫—ñ –Ω–∞–≤–∏—á–∫–∏
        "communication", "teamwork", "leadership", "problem solving", "time management",
        "adaptability", "critical thinking", "creativity", "attention to detail", "organization",
        # üñ• IT
        "python", "java", "c++", "sql", "html", "css", "javascript", "git", "linux", "docker",
        "data analysis", "machine learning", "deep learning", "tensorflow", "pandas", "numpy",
        "power bi", "excel", "tableau", "aws", "azure", "cloud", "api development",
        # üìä –ë—ñ–∑–Ω–µ—Å
        "microsoft office", "word", "powerpoint", "erp", "sap", "crm", "data entry",
        "project management", "budgeting", "salesforce", "accounting", "forecasting",
        # üõ† –†–æ–±—ñ—Ç–Ω–∏—á—ñ
        "welding", "carpentry", "plumbing", "electrical", "machinery operation", "maintenance",
        "blueprint reading", "forklift operation", "repair", "construction",
        # üçΩ –°—Ñ–µ—Ä–∞ –æ–±—Å–ª—É–≥–æ–≤—É–≤–∞–Ω–Ω—è
        "customer service", "cash handling", "order taking", "food preparation", "cooking",
        "bartending", "dishwashing", "cleaning", "POS systems", "inventory",
        # üöõ –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç
        "driving", "truck driving", "navigation", "route planning", "vehicle maintenance",
        "logistics", "delivery", "loading", "unloading", "warehouse management",
        # üßë‚Äç‚öïÔ∏è –ú–µ–¥–∏—Ü–∏–Ω–∞
        "first aid", "patient care", "medication administration", "vital signs", "nursing",
        "record keeping", "elder care", "childcare", "rehabilitation", "sanitation",
        # üé® –ö—Ä–µ–∞—Ç–∏–≤
        "photoshop", "illustrator", "graphic design", "video editing", "photography",
        "social media", "marketing", "branding", "content creation",
        # üìû –ê–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ñ
        "filing", "scheduling", "call handling", "typing", "office management",
        "calendar management", "email management", "document preparation", "clerical duties"
    ]
    profession_keywords = ["C Developer", "Java Developer", "Data Scientist", "Project Manager", "UI/UX designer", "Graphic designer", "QA engineer", "HR", "Data Analyst", "System administrator", "data science", "java developer", "UI/UX designer", "project manager", "graphic designer"]

    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
    classified = {
        "experience": {
            "years": [],
            "total_experience_years": 0
        },
        "education": [],
        "skills": [],
        "profession": [],
        "other": []
    }

    year_pattern = re.compile(r"\b(19[5-9]\d|20[0-4]\d|2050)\b")  # —Ä–æ–∫–∏ –≤—ñ–¥ 1950 –¥–æ 2050

    for ent in entities:
        text_lower = ent.text.lower()
        label = ent.label_

        # üî¢ –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —Ä–æ–∫—É
        years_found = year_pattern.findall(ent.text)
        if years_found:
            classified["experience"]["years"].extend(map(int, years_found))
            continue  # –≤–∂–µ –∫–ª–∞—Å–∏—Ñ—ñ–∫–æ–≤–∞–Ω–æ

        if label in ["ORG", "GPE"] and any(word in text_lower for word in education_keywords):
            classified["education"].append(ent.text)
        elif any(word in text_lower for word in skill_keywords):
            classified["skills"].append(ent.text)
        elif any(word in text_lower for word in profession_keywords):
            classified["profession"].append(ent.text)
        else:
            classified["other"].append(ent.text)

    # üîÅ –û–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–æ—Å–≤—ñ–¥—É
    years = classified["experience"]["years"]
    if years:
        classified["experience"]["total_experience_years"] = max(years) - min(years)

    return classified


def extract_and_classify_entities(file_path):

    with open(file_path, 'r', encoding='utf-8') as file:
        text = file.read()

    doc = nlp(text)
    return classify_entities(doc.ents)

def check_for_english(tags):
    eng_doc = nlp("english")
    for other in tags["other"]:
        other_doc = nlp(other.lower())
        if eng_doc.has_vector and other_doc.has_vector:
            if eng_doc.similarity(other_doc) > 0.65:
                return True
    return False

def check_for_profession(tags, profession):
    prof_doc = nlp(profession.lower())
    for other in tags["profession"]:
        print(other)
        other_doc = nlp(other.lower())
        if prof_doc.has_vector and other_doc.has_vector:
            koef = prof_doc.similarity(other_doc)
            print("profession: ", koef)
            if koef > 0.3:
                return True
    return False


def check_education_level(tags):
    education_keywords = {
        "Secondary Education": ["school", "high school", "secondary education"],
        "Vocational Education": ["college", "vocational", "trade school", "community college"],
        "Higher Education": ["university", "academy", "institute", "bachelor", "ba", "bsc"],
        "Graduate Degree": ["phd", "doctor of philosophy", "master", "ma", "msc"]
    }

    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø–æ—Ä—è–¥–æ–∫ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç—É —Ä—ñ–≤–Ω—ñ–≤ –æ—Å–≤—ñ—Ç–∏ –≤—ñ–¥ –Ω–∏–∑—å—à–æ–≥–æ –¥–æ –≤–∏—â–æ–≥–æ
    priority = ["Secondary Education", "Vocational Education", "Higher Education", "Graduate Degree"]

    combined_tags = tags["education"] + tags["other"]

    found_levels = set()

    for level, keywords in education_keywords.items():
        for tag_text in combined_tags:
            norm_text = tag_text.lower()
            norm_text = re.sub(r'[^\w\s]', '', norm_text)
            if any(keyword in norm_text for keyword in keywords):
                found_levels.add(level)

    # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ –Ω—ñ—á–æ–≥–æ ‚Äî –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ Unknown
    if not found_levels:
        return "Unknown"

    # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –Ω–∞–π–∫—Ä–∞—â–∏–π —Ä—ñ–≤–µ–Ω—å –∑–∞ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–æ–º
    for level in reversed(priority):  # –ø–æ—á–∏–Ω–∞—î–º–æ –∑ –Ω–∞–π–≤–∏—â–æ–≥–æ
        if level in found_levels:
            return level


# ‚úÖ –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç–∞ –¥–æ—Å–≤—ñ–¥—É
def get_experience_k(result, desired_years):
    """
    –ü–æ–≤–µ—Ä—Ç–∞—î –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –¥–æ—Å–≤—ñ–¥—É: —Ñ–∞–∫—Ç–∏—á–Ω–∏–π / –±–∞–∂–∞–Ω–∏–π (–æ–±–º–µ–∂–µ–Ω–∏–π 1.0 –º–∞–∫—Å–∏–º—É–º–æ–º)
    """
    actual_years = result["experience"]["total_experience_years"]

    if desired_years == 0:
        return 1.0 if actual_years > 0 else 0.0  # —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ 0

    ratio = actual_years / desired_years
    return round(min(ratio, 1.0), 2)



# ‚úÖ –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç–∞ –æ—Å–≤—ñ—Ç–∏
def get_education_k(result, desired_level):
    edu_weights = {
        "Graduate Degree": {
            "Secondary Education": 0.25,
            "Vocational Education": 0.5,
            "Higher Education": 0.75,
            "Graduate Degree": 1.0
        },
        "Higher Education": {
            "Secondary Education": 0.5,
            "Vocational Education": 0.75,
            "Higher Education": 1.0,
            "Graduate Degree": 1.0,
            "_": 0.25
        },
        "Vocational Education": {
            "Secondary Education": 0.75,
            "Vocational Education": 1.0,
            "Higher Education": 1.0,
            "Graduate Degree": 1.0,
            "_": 0.5
        },
        "Secondary Education": {
            "Secondary Education": 1.0,
            "Vocational Education": 1.0,
            "Higher Education": 1.0,
            "Graduate Degree": 1.0,
            "_": 0.75
        }
    }

    education_level = check_education_level(result)
    # print(f"üìò Education Level: {education_level}")
    return edu_weights.get(desired_level, {}).get(education_level, edu_weights.get(desired_level, {}).get("_", 1.0))


def smart_match(tags, required_skills, nlp, sim_threshold=0.6):
    """
    –°–ø–æ—á–∞—Ç–∫—É —Ç–æ—á–Ω–∏–π –∑–±—ñ–≥ –ª–µ–º, –ø–æ—Ç—ñ–º –≤–µ–∫—Ç–æ—Ä–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç—ñ–ª—å–∫–∏ –¥–ª—è –Ω–µ–∑–±—ñ–≥–ª–∏—Ö.
    –õ–µ–º–∞—Ç–∏–∑–∞—Ü—ñ—è –∫–æ–∂–Ω–æ–≥–æ —Å–ª–æ–≤–∞ –æ–∫—Ä–µ–º–æ, –∞ –Ω–µ –≤—Å—å–æ–≥–æ —Å–ø–∏—Å–∫—É —è–∫ –æ–¥–Ω–æ–≥–æ —Ä–µ—á–µ–Ω–Ω—è.
    """
    # –û–±'—î–¥–Ω—É—î–º–æ –≤—Å—ñ —Å–ª–æ–≤–∞ –∑ —Ä–µ–∑—é–º–µ (skills + other)
    resume_words = tags["skills"] + tags["other"]

    # –õ–µ–º–∞—Ç–∏–∑—É—î–º–æ –∫–æ–∂–Ω–µ —Å–ª–æ–≤–æ –æ–∫—Ä–µ–º–æ –≤ —Ä–µ–∑—é–º–µ
    resume_lemmas = set()
    for word in resume_words:
        doc = nlp(word)
        for token in doc:
            # –î–æ–¥–∞—î–º–æ –í–°–Ü —Ç–æ–∫–µ–Ω–∏, –∫—Ä—ñ–º –ø—Ä–æ–±—ñ–ª—ñ–≤ —ñ –ø—É–Ω–∫—Ç—É–∞—Ü—ñ—ó
            resume_lemmas.add(token.text.lower())

    # –õ–µ–º–∞—Ç–∏–∑—É—î–º–æ –∫–æ–∂–Ω–µ —Å–ª–æ–≤–æ –æ–∫—Ä–µ–º–æ –≤ required_skills
    required_lemmas = []
    for word in required_skills:
        doc = nlp(word.lower())
        for token in doc:
            # –î–æ–¥–∞—î–º–æ –í–°–Ü —Ç–æ–∫–µ–Ω–∏, –∫—Ä—ñ–º –ø—Ä–æ–±—ñ–ª—ñ–≤ —ñ –ø—É–Ω–∫—Ç—É–∞—Ü—ñ—ó
            required_lemmas.append(token.text.lower())

    matched = []
    unmatched = []

    # –ö—Ä–æ–∫ 1 ‚Äî —Ç–æ—á–Ω–∏–π –∑–±—ñ–≥
    for lemma in required_lemmas:
        if lemma in resume_lemmas:
            matched.append(lemma)
        else:
            unmatched.append(lemma)

    # –ö—Ä–æ–∫ 2 ‚Äî —Å–µ–º–∞–Ω—Ç–∏—á–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç—ñ–ª—å–∫–∏ –¥–ª—è unmatched
    for word in unmatched[:]:  # –∫–æ–ø—ñ—è —Å–ø–∏—Å–∫—É
        word_doc = nlp(word)
        for res_lemma in resume_lemmas:
            res_doc = nlp(res_lemma)
            if word_doc.has_vector and res_doc.has_vector:
                if word_doc.similarity(res_doc) >= sim_threshold:
                    matched.append(word)
                    unmatched.remove(word)
                    break

    # –†–µ–∑—É–ª—å—Ç–∞—Ç
    skills_k = len(matched) / len(required_lemmas) if required_lemmas else 0

    print("\nüîç Smart match (step 1: exact + step 2: semantic only for leftovers)")
    print(f"  ‚úÖ Matched: {matched}")
    print(f"  ‚ùå Not matched: {unmatched}")
    print(f"  üìä Skills koef: {skills_k:.2f}")

    return skills_k


def analyse_resume(folder_path, experience, english, skills, profession, education):
    print("Let`s start!")
    print(folder_path)
    print(experience)
    print(english)
    print(skills)
    print(profession)
    print(education)
    iterator = 1
    utc_now = datetime.now(timezone.utc)
    formatted = utc_now.strftime("%H_%M_%d_%m_%Y")
    result_name = "evaluation_results_" + formatted
    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)
        result = extract_and_classify_entities(file_path)

        if profession != "Any":
            if not check_for_profession(result, profession):
                continue

        if education != "Any" :
            education_k = get_education_k(result, education)
        else: education_k = 1

        skills_k = smart_match(result, skills, nlp)
        if experience == "Any":
            experience_k = 1
        else: experience_k = get_experience_k(result, experience)

        print(f"{iterator}.{experience_k}, {skills_k}, {education_k}")
        iterator += 1

        k1 = 0.3
        k2 = 0.2
        k3 = 0.5
        k4 = 1.04
        final_score = k1 * experience_k + k2 * education_k + k3 * skills_k
        if english and check_for_english(result):
            final_score = final_score * k4
        elif not english:
            final_score = final_score * k4

        # if final_score >= 60.0:
        print(f"<UNK> {filename} - final score: {final_score:.2f}")

        with open(result_name, "a") as f:
            f.write(f"{filename} - final score: {final_score:.2f}\n")

    os.startfile(result_name)